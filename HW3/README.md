# Machine Learning Homework: Regression Methods Comparison

## Project Overview
This homework explores regression techniques through theoretical and practical approaches using the `kin8nm.arff` dataset, focusing on Linear Regression and Multi-Layer Perceptron (MLP) models.

## Theoretical Tasks
The theoretical component involves:
- Implementing 3rd-order polynomial Ridge regression
- Calculating training Root Mean Square Error (RMSE)
- Performing manual gradient descent on a neural network with custom activation function

## Programming Implementation
The programming tasks require:
- Comparing three regression models:
  1. Linear Regression with Ridge regularization (Î» = 0.1)
  2. MLP1 with early stopping
  3. MLP2 without early stopping
- Using a 70-30 train-test split
- Calculating Mean Absolute Error (MAE)
- Visualizing residuals through boxplots and histograms
- Analyzing model convergence characteristics

## Key Technical Components
- Regression Algorithms:
  - Linear Regression (Ridge)
  - Multi-Layer Perceptron (MLP)
- Regularization Techniques
- Model Evaluation Metrics:
  - Mean Absolute Error (MAE)
  - Residual Analysis
- Visualization Methods:
  - Boxplots
  - Histograms
- Neural Network Parameters:
  - Two hidden layers (10 nodes each)
  - Hyperbolic tangent activation function
  - Maximum 500 iterations

## Objectives
- Compare performance of different regression techniques
- Understand impact of early stopping on neural network training
- Analyze model convergence and residual characteristics
- Develop skills in regression model implementation and evaluation
